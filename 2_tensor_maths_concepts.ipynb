{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c747cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10dd838f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import helper_utils\n",
    "\n",
    "# This line ensures that your results are reproducible and consistent every time.\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6602c8a",
   "metadata": {},
   "source": [
    "## Tensor shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fde502c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.],\n",
      "        [ 7.],\n",
      "        [11.],\n",
      "        [15.],\n",
      "        [19.],\n",
      "        [23.]])\n",
      "torch.float32\n",
      "torch.Size([6, 1])\n",
      "------------\n",
      "tensor([[ 0.2158],\n",
      "        [-0.7213],\n",
      "        [-1.6584],\n",
      "        [-2.5955],\n",
      "        [-3.5326],\n",
      "        [-4.4697]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# distance\n",
    "distances = torch.tensor([[3.0], [7.0], [11.0], [15.0], [19.0], [23.0]])\n",
    "print(distances)\n",
    "print(distances.dtype)\n",
    "print(distances.shape)  # torch.Size([6, 1])\n",
    "print(\"------------\")\n",
    "simple_model = nn.Linear(in_features=1, out_features=1)\n",
    "output = simple_model(distances)\n",
    "print(output)  # tensor with shape torch.Size([6, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbfff6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "tensor([[-1.7130],\n",
      "        [-1.9893],\n",
      "        [-2.7746],\n",
      "        [-4.0689],\n",
      "        [-4.8541]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# distance, hour, weather\n",
    "distances = torch.tensor([[7.0, 2.0, 0.0], [11.0, 3.0, 1.0], [15.0, 4.0, 1.0], [19.0, 5.0, 0.0], [23.0, 6.0, 0.0]])\n",
    "print(distances.shape)  # torch.Size([5, 3])\n",
    "simple_model = nn.Linear(in_features=3, out_features=1)\n",
    "output = simple_model(distances)\n",
    "print(output)  # tensor with shape torch.Size([5, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3317a71b",
   "metadata": {},
   "source": [
    "## Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "780d7e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "tensor(7.)\n"
     ]
    }
   ],
   "source": [
    "# Single value tensor\n",
    "single_value_tensor = torch.tensor(7.0)\n",
    "print(single_value_tensor.shape)  # torch.Size([])\n",
    "print(single_value_tensor)  # tensor(7.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efe557c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "tensor([7.])\n"
     ]
    }
   ],
   "source": [
    "single_value_tensor = single_value_tensor.unsqueeze(0)  # add a dimension\n",
    "print(single_value_tensor.shape)  # torch.Size([1])\n",
    "print(single_value_tensor)  # tensor([7.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc4ee5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "tensor([[0.7886, 0.5895, 0.7539, 0.1952],\n",
      "        [0.0050, 0.3068, 0.1165, 0.9103]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand(2, 4)\n",
    "print(random_tensor.shape)  # torch.Size([2, 4])\n",
    "print(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efb80b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "my_distances = [[3.0], [7.0], [11.0], [15.0], [19.0], [23.0]]\n",
    "tensor_distances = torch.tensor(my_distances)\n",
    "print(tensor_distances.shape)  # torch.Size([6, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f9736ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "array_distances = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "tensor_distances = torch.from_numpy(array_distances)\n",
    "print(tensor_distances.shape)  # torch.Size([5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd58256",
   "metadata": {},
   "source": [
    "## Tensor math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ca4c943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14.9000],\n",
      "        [24.1000],\n",
      "        [35.6000]])\n"
     ]
    }
   ],
   "source": [
    "distances_arr = [[3.0], [7.0], [12.0]]\n",
    "distances = torch.tensor(distances_arr)\n",
    "weights = torch.tensor(2.3)\n",
    "bias = torch.tensor(8.0)\n",
    "print(weights * distances + bias)  # tensor math operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7eeed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.9000\n",
      "24.1000\n",
      "35.6000\n"
     ]
    }
   ],
   "source": [
    "# print round 2 digits after decimal\n",
    "print(f\"{round(2.3 * 3.0 + 8.0, 2):.4f}\")\n",
    "print(f\"{round(2.3 * 7.0 + 8.0, 2):.4f}\")\n",
    "print(f\"{round(2.3 * 12.0 + 8.0, 2):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7529ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[0.9000, 1.8000, 2.7000],\n",
      "        [3.6000, 4.5000, 5.4000]])\n"
     ]
    }
   ],
   "source": [
    "matrix_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(matrix_tensor.shape)  # torch.Size([2, 3])\n",
    "print(matrix_tensor)  # tensor([[1, 2, 3], [4, 5, 6]])\n",
    "matrix_tensor_discounted = matrix_tensor * 0.9\n",
    "print(matrix_tensor_discounted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df05d952",
   "metadata": {},
   "source": [
    "### Exercises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3223143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL SALES DATA:\n",
      "\n",
      " tensor([[100., 120., 130., 110.],\n",
      "        [ 90.,  95., 105., 125.],\n",
      "        [140., 115., 120., 150.]])\n",
      "---------------------------------------------\n",
      "Sales data for Product B\n",
      "tensor([ 90.,  95., 105., 125.])\n",
      "tensor(415.)\n",
      "tensor([ True, False, False,  True])\n",
      "tensor([[120., 130.],\n",
      "        [ 95., 105.],\n",
      "        [115., 120.]])\n"
     ]
    }
   ],
   "source": [
    "# Sales data for 3 products over 4 months\n",
    "sales_data = torch.tensor([[100, 120, 130, 110],   # Product A\n",
    "                           [ 90,  95, 105, 125],   # Product B\n",
    "                           [140, 115, 120, 150]    # Product C\n",
    "                          ], dtype=torch.float32)\n",
    "\n",
    "print(\"ORIGINAL SALES DATA:\\n\\n\", sales_data)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "# 1. Calculate total sales for Product B.\n",
    "print(\"Sales data for Product B\")\n",
    "print(sales_data[1])\n",
    "total_sales_product_b = sales_data[1].sum()\n",
    "print(total_sales_product_b)\n",
    "\n",
    "# 2. Find months where sales for Product C were > 130.\n",
    "mask = sales_data[2] > 130\n",
    "print(mask)\n",
    "high_sales_mask_product_c = mask\n",
    "\n",
    "# 3. Get sales for Feb and Mar for all products.\n",
    "\n",
    "sales_feb_mar = sales_data[:, 1:3]\n",
    "print(sales_feb_mar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f762bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL BATCH SHAPE: torch.Size([4, 3, 3])\n",
      "---------------------------------------------\n",
      "ORIGINAL BATCH SHAPE: torch.Size([4, 1, 3, 3])\n",
      "---------------------------------------------\n",
      "image_batch_transposed: torch.Size([4, 3, 3, 1])\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# A batch of 4 grayscale images, each 3x3\n",
    "image_batch = torch.rand(4, 3, 3)\n",
    "\n",
    "print(\"ORIGINAL BATCH SHAPE:\", image_batch.shape)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "# 1. Add a channel dimension at index 1.\n",
    "image_batch_with_channel = image_batch.unsqueeze(1)\n",
    "print(\"ORIGINAL BATCH SHAPE:\", image_batch_with_channel.shape)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# 2. Transpose the tensor to move the channel dimension to the end.\n",
    "# image_batch_with_channel is [batch_size, channels, height, width]\n",
    "# image_batch_with_channel is [batch_size, height, width, channels]\n",
    "# Swap dimension 1 (channels) with dimension 3 (the last one).\n",
    "image_batch_transposed = image_batch_with_channel.transpose(1, 3)\n",
    "print(\"image_batch_transposed:\", image_batch_transposed.shape)\n",
    "print(\"-\" * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af08b96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPERATURE DATA:  tensor([22.5000, 23.1000, 21.9000, 22.8000, 23.5000])\n",
      "TEMPERATURE DATA SHAPE:  torch.Size([5])\n",
      "HUMIDITY DATA:     tensor([55.2000, 56.4000, 54.8000, 57.1000, 56.8000])\n",
      "HUMIDITY DATA SHAPE:  torch.Size([5])\n",
      "---------------------------------------------\n",
      "\n",
      "COMBINED DATA (2x5):\n",
      "\n",
      " None\n",
      "\n",
      "WEIGHTED DATA:\n",
      "\n",
      " None\n",
      "\n",
      "WEIGHTED AVERAGE: None\n"
     ]
    }
   ],
   "source": [
    "# Sensor readings (5 time steps)\n",
    "temperature = torch.tensor([22.5, 23.1, 21.9, 22.8, 23.5])\n",
    "humidity = torch.tensor([55.2, 56.4, 54.8, 57.1, 56.8])\n",
    "\n",
    "print(\"TEMPERATURE DATA: \", temperature)\n",
    "print(\"TEMPERATURE DATA SHAPE: \", temperature.shape)\n",
    "print(\"HUMIDITY DATA:    \", humidity)\n",
    "print(\"HUMIDITY DATA SHAPE: \", humidity.shape)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "# 1. Concatenate the two tensors.\n",
    "# Note: You need to unsqueeze them first to stack them vertically.\n",
    "combined_data = None\n",
    "\n",
    "# 2. Create the weights tensor.\n",
    "weights = None\n",
    "\n",
    "# 3. Apply weights using broadcasting.\n",
    "# You need to reshape weights to [2, 1] to broadcast across columns.\n",
    "weighted_data = None\n",
    "\n",
    "# 4. Calculate the weighted average for each time step.\n",
    "weighted_average = None\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(\"\\nCOMBINED DATA (2x5):\\n\\n\", combined_data)\n",
    "print(\"\\nWEIGHTED DATA:\\n\\n\", weighted_data)\n",
    "print(\"\\nWEIGHTED AVERAGE:\", weighted_average)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-for-deep-learning (3.11.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
